{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20MinsNLP 20190402-Coreference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wannaphongcom/th-ud/blob/master/20MinsNLP_20190402_Coreference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njNnJUJ0FZYa",
        "colab_type": "text"
      },
      "source": [
        "# 20Mins NLP: Coreference Resolution\n",
        "2019-04-02\n",
        "\n",
        "Welcome to my first session of the 20Mins NLP. In this session we will build a coreference system from scratch. The system is a simplified version of the state-of-the-art Lee et al., (2017) system, which is based on the mention ranking algorithm.\n",
        "\n",
        "##Obtain the data\n",
        "In order to run this notebook you will need first download some datasets and pre-trained word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13x24pBCHyrP",
        "colab_type": "code",
        "outputId": "cb01c793-a39a-47a2-d5dc-cc521dc0b9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!wget http://vectors.nlpl.eu/repository/11/8.zip\n",
        "!unzip 8.zip\n",
        "!rm 8.zip \n",
        "!git clone https://github.com/juntaoy/20MinsNLP-2019-04-02-Coreference-Data.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-27 16:59:23--  http://vectors.nlpl.eu/repository/11/8.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 334196260 (319M) [application/zip]\n",
            "Saving to: ‘8.zip’\n",
            "\n",
            "8.zip               100%[===================>] 318.71M  79.0MB/s    in 4.8s    \n",
            "\n",
            "2019-03-27 16:59:28 (66.4 MB/s) - ‘8.zip’ saved [334196260/334196260]\n",
            "\n",
            "Archive:  8.zip\n",
            "  inflating: model.txt               \n",
            "  inflating: README                  \n",
            " extracting: meta.json               \n",
            "Cloning into '20MinsNLP-2019-04-02-Coreference-Data'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 14 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (14/14), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sop0tMi-MAc-",
        "colab_type": "text"
      },
      "source": [
        "##Some help methods\n",
        "Then we have some help method which make the life easier.\n",
        "\n",
        "###The shape() method helps us get the n-th dimension of a given tensor.\n",
        "In tensorflow there are two ways of getting a tensor’s shape. The  `Tensor.get_shape()[n]` method can get a predefined dimension of the tensor,  such as the last dimension of the word_embeddings (300) or the dimension of the hidden layer (for both LSTM and FFNN is 150). The second method (`tf.shape()[n]`) returns the dynamic size of the tensor, such as the number of sentences or the number of mentions. Those sizes are not fixed across different documents thus are dynamic.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov3eOd3HNzfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shape(x, n):\n",
        "  return x.get_shape()[n].value or tf.shape(x)[n]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsgAS2SPN0pI",
        "colab_type": "text"
      },
      "source": [
        "###The time_used() method outputs the time differences between the current time and the input time.\n",
        "It is always a good practice to record the time usage of individual process, so you always known which part is most expensive to run.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBzcEreAOHKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def time_used(start_time):\n",
        "  curr_time = time.time()\n",
        "  used_time = curr_time-start_time\n",
        "  m = used_time // 60\n",
        "  s = used_time - 60 * m\n",
        "  return \"%d m %d s\" % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tkS4vWaP_W7",
        "colab_type": "text"
      },
      "source": [
        "###The standard coreference evaluation metric\n",
        "The code is able to compute the standard coreference evaluation metrics (MUC, B-cubed and Ceafe), and return the CoNLL average score (average F1 of MUC, B-cubed and Ceafe) we needed for evaluating our system.\n",
        "The code is taken from Lee et al., (2017) system which orignally created by Clark and Manning (2016). You don't have to understand this in order to run the coreference system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqYCQSXsRyAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.utils.linear_assignment_ import linear_assignment\n",
        "\n",
        "\"\"\"\n",
        "Mostly borrowed from https://github.com/clarkkev/deep-coref/blob/master/evaluation.py\n",
        "\"\"\"\n",
        "\n",
        "def f1(p_num, p_den, r_num, r_den, beta=1):\n",
        "    p = 0 if p_den == 0 else p_num / float(p_den)\n",
        "    r = 0 if r_den == 0 else r_num / float(r_den)\n",
        "    return 0 if p + r == 0 else (1 + beta * beta) * p * r / (beta * beta * p + r)\n",
        "\n",
        "class CorefEvaluator(object):\n",
        "    def __init__(self):\n",
        "        self.evaluators = [Evaluator(m) for m in (muc, b_cubed, ceafe)]\n",
        "\n",
        "    def update(self, predicted, gold, mention_to_predicted, mention_to_gold):\n",
        "        for e in self.evaluators:\n",
        "            e.update(predicted, gold, mention_to_predicted, mention_to_gold)\n",
        "\n",
        "    def get_f1(self):\n",
        "        return sum(e.get_f1() for e in self.evaluators) / len(self.evaluators)\n",
        "\n",
        "    def get_recall(self):\n",
        "        return sum(e.get_recall() for e in self.evaluators) / len(self.evaluators)\n",
        "\n",
        "    def get_precision(self):\n",
        "        return sum(e.get_precision() for e in self.evaluators) / len(self.evaluators)\n",
        "\n",
        "    def get_prf(self):\n",
        "        return self.get_precision(), self.get_recall(), self.get_f1()\n",
        "\n",
        "class Evaluator(object):\n",
        "    def __init__(self, metric, beta=1):\n",
        "        self.p_num = 0\n",
        "        self.p_den = 0\n",
        "        self.r_num = 0\n",
        "        self.r_den = 0\n",
        "        self.metric = metric\n",
        "        self.beta = beta\n",
        "\n",
        "    def update(self, predicted, gold, mention_to_predicted, mention_to_gold):\n",
        "        if self.metric == ceafe:\n",
        "            pn, pd, rn, rd = self.metric(predicted, gold)\n",
        "        else:\n",
        "            pn, pd = self.metric(predicted, mention_to_gold)\n",
        "            rn, rd = self.metric(gold, mention_to_predicted)\n",
        "        self.p_num += pn\n",
        "        self.p_den += pd\n",
        "        self.r_num += rn\n",
        "        self.r_den += rd\n",
        "\n",
        "    def get_f1(self):\n",
        "        return f1(self.p_num, self.p_den, self.r_num, self.r_den, beta=self.beta)\n",
        "\n",
        "    def get_recall(self):\n",
        "        return 0 if self.r_num == 0 else self.r_num / float(self.r_den)\n",
        "\n",
        "    def get_precision(self):\n",
        "        return 0 if self.p_num == 0 else self.p_num / float(self.p_den)\n",
        "\n",
        "    def get_prf(self):\n",
        "        return self.get_precision(), self.get_recall(), self.get_f1()\n",
        "\n",
        "    def get_counts(self):\n",
        "        return self.p_num, self.p_den, self.r_num, self.r_den\n",
        "\n",
        "\n",
        "def evaluate_documents(documents, metric, beta=1):\n",
        "    evaluator = Evaluator(metric, beta=beta)\n",
        "    for document in documents:\n",
        "        evaluator.update(document)\n",
        "    return evaluator.get_precision(), evaluator.get_recall(), evaluator.get_f1()\n",
        "\n",
        "\n",
        "def b_cubed(clusters, mention_to_gold):\n",
        "    num, dem = 0, 0\n",
        "\n",
        "    for c in clusters:\n",
        "        if len(c) == 1:\n",
        "            continue\n",
        "\n",
        "        gold_counts = Counter()\n",
        "        correct = 0\n",
        "        for m in c:\n",
        "            if m in mention_to_gold:\n",
        "                gold_counts[tuple(mention_to_gold[m])] += 1\n",
        "        for c2, count in gold_counts.iteritems():\n",
        "            if len(c2) != 1:\n",
        "                correct += count * count\n",
        "\n",
        "        num += correct / float(len(c))\n",
        "        dem += len(c)\n",
        "\n",
        "    return num, dem\n",
        "\n",
        "\n",
        "def muc(clusters, mention_to_gold):\n",
        "    tp, p = 0, 0\n",
        "    for c in clusters:\n",
        "        p += len(c) - 1\n",
        "        tp += len(c)\n",
        "        linked = set()\n",
        "        for m in c:\n",
        "            if m in mention_to_gold:\n",
        "                linked.add(mention_to_gold[m])\n",
        "            else:\n",
        "                tp -= 1\n",
        "        tp -= len(linked)\n",
        "    return tp, p\n",
        "\n",
        "\n",
        "def phi4(c1, c2):\n",
        "    return 2 * len([m for m in c1 if m in c2]) / float(len(c1) + len(c2))\n",
        "\n",
        "\n",
        "def ceafe(clusters, gold_clusters):\n",
        "    clusters = [c for c in clusters if len(c) != 1]\n",
        "    scores = np.zeros((len(gold_clusters), len(clusters)))\n",
        "    for i in range(len(gold_clusters)):\n",
        "        for j in range(len(clusters)):\n",
        "            scores[i, j] = phi4(gold_clusters[i], clusters[j])\n",
        "    matching = linear_assignment(-scores)\n",
        "    similarity = sum(scores[matching[:, 0], matching[:, 1]])\n",
        "    return similarity, len(clusters), similarity, len(gold_clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVf8ITRuH80S",
        "colab_type": "text"
      },
      "source": [
        "##The main components for our coreference resolution system\n",
        "Now you are ready to go! Let first create a single class (CorefModel) to store all the elements we needed for our simple coreference system. \n",
        "\n",
        "###In the \\__init__() method we intialize the network parameters.\n",
        "Here we hardcoded them. For a real system, usually, the parameters will be stored in a configuration file, as there will be many of them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXacYXq7Ijmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import collections\n",
        "\n",
        "class CorefModel(object):\n",
        "  def __init__(self,embedding_path, embedding_size):\n",
        "    tf.reset_default_graph()\n",
        "    self.embedding_path = embedding_path #The path to the pre-trained word embeddings\n",
        "    self.embedding_size = embedding_size #The dimension of the pretrained embeddings\n",
        "    self.embedding_dropout_rate = 0.5 #The dropout rate for word embeddings\n",
        "    self.max_ant = 250 #The maximum number of candidate antecedents we will give to each of the candidate mentions.\n",
        "    self.hidden_size = 150 #The size of the hidden layer, include both LSTM and feedforward NN\n",
        "    self.ffnn_layer = 2 #The number of hidden layers used for the feedforward NN\n",
        "    self.hidden_dropout_rate = 0.2 #The dropout rate for the hidden layers of LSTM and feedforward NN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anC9NTFqKS2w",
        "colab_type": "text"
      },
      "source": [
        "###The build() method builds a tensorflow graph for our task\n",
        "This method first loads the pre-trained word embeddings from the given location by calling the `load_embeddings` method:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7AvIgibKfMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def load_embeddings(self, path, size):\n",
        "    print(\"Loading word embeddings from {}...\".format(path))\n",
        "    embeddings = collections.defaultdict(lambda: np.zeros(size))\n",
        "    firstline=True\n",
        "    for line in open(path):\n",
        "      if firstline:\n",
        "        firstline=False\n",
        "        continue\n",
        "      splitter = line.find(' ')\n",
        "      emb = np.fromstring(line[splitter + 1:], np.float32, sep=' ')\n",
        "      assert len(emb) == size\n",
        "      embeddings[line[:splitter]] = emb\n",
        "    print(\"Finished loading word embeddings\")\n",
        "    return embeddings\n",
        "  CorefModel.load_embeddings = load_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snpDg8tMKyCe",
        "colab_type": "text"
      },
      "source": [
        "It then creates placeholders, which are the inputs of the tensorflow graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muZTjdNAxi8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def add_placeholder(self):\n",
        "    self.word_embeddings = tf.placeholder(tf.float32, shape=[None, None,self.embedding_size])\n",
        "    self.sent_lengths = tf.placeholder(tf.int32, shape=[None])\n",
        "    self.mention_starts = tf.placeholder(tf.int32, shape=[None])\n",
        "    self.mention_ends = tf.placeholder(tf.int32, shape=[None])\n",
        "    self.mention_cluster_ids = tf.placeholder(tf.int32, shape=[None])\n",
        "    self.is_training = tf.placeholder(tf.bool, shape=[])\n",
        "  CorefModel.add_placeholder = add_placeholder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBtTfHB0xjTG",
        "colab_type": "text"
      },
      "source": [
        " After that, the method calls the `get_predictions_and_loss` method to create the rest of the tensorflow graph. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGFqGleMxnjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def get_predictions_and_loss(self,word_embeddings,sent_lengths,mention_starts,mention_ends,mention_cluster_ids,is_training):\n",
        "    #get the keep probability\n",
        "    embedding_keep_prob = 1 - (tf.to_float(is_training)*self.embedding_dropout_rate)\n",
        "    hidden_keep_prob = 1 - (tf.to_float(is_training)*self.hidden_dropout_rate)\n",
        "\n",
        "\n",
        "    #bidirectional LSTM over sentences\n",
        "    word_embeddings = tf.nn.dropout(word_embeddings,embedding_keep_prob)\n",
        "    word_lstm_for = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(self.hidden_size),\n",
        "                                                  state_keep_prob=hidden_keep_prob,\n",
        "                                                  variational_recurrent=True,\n",
        "                                                  dtype=tf.float32)\n",
        "    word_lstm_rev = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(self.hidden_size),\n",
        "                                                  state_keep_prob=hidden_keep_prob,\n",
        "                                                  variational_recurrent=True,\n",
        "                                                  dtype=tf.float32)\n",
        "    (output_for, output_rev), _ = tf.nn.bidirectional_dynamic_rnn(\n",
        "      word_lstm_for, word_lstm_rev, word_embeddings,\n",
        "      sequence_length=sent_lengths, dtype=tf.float32\n",
        "    )\n",
        "\n",
        "\n",
        "    word_output = tf.concat([output_for, output_rev], axis=-1) #[num_sent,2*hidden_size]\n",
        "    \n",
        "    #remove paddings from the word output\n",
        "    num_sents = shape(word_embeddings, 0)\n",
        "    max_sent_length = shape(word_embeddings, 1)\n",
        "    \n",
        "    word_seq_mask = tf.sequence_mask(sent_lengths, max_sent_length) #[num_sent, max_sent_len]\n",
        "    flatten_word_seq_mask = tf.reshape(word_seq_mask, [num_sents * max_sent_length]) #[num_sent*max_sent_len]\n",
        "    flatten_word_output = tf.reshape(word_output, [num_sents * max_sent_length, 2 * self.hidden_size]) #[num_sent*max_sent_len, 2*hidden_size]\n",
        "    flatten_word_output = tf.nn.dropout(flatten_word_output, hidden_keep_prob) #[num_sent*max_sent_len, 2*hidden_size]\n",
        "    flatten_word_output = tf.boolean_mask(flatten_word_output, flatten_word_seq_mask, axis=0) #[num_words, 2*hidden_size]\n",
        "    \n",
        "    #create the mention representation from the word output \n",
        "    #by concatenating word_output at the positions of mention’s start and end indices\n",
        "    mention_starts_emb = tf.gather(flatten_word_output,mention_starts) #[num_mentions,2*hidden_size]\n",
        "    mention_ends_emb = tf.gather(flatten_word_output,mention_ends)#[num_mentions, 2*hidden_size]\n",
        "    mention_emb = tf.concat([mention_starts_emb,mention_ends_emb],axis=1) #[num_mentions,4*hidden_size]\n",
        "    \n",
        "    #In order to do coreference, we also need to create the candidate antecedents.\n",
        "    #Here we give each of the candidate mentions a maximum 250 candidate antecedents\n",
        "    #(candidate mentions that before the current mention).\n",
        "    num_mention = shape(mention_emb, 0) \n",
        "    max_ant = tf.minimum(num_mention,self.max_ant)\n",
        "    antecedents = tf.expand_dims(tf.range(num_mention),1) \\\n",
        "                  - tf.tile(tf.expand_dims(tf.range(max_ant)+1, 0), [num_mention, 1]) #[num_mentions,max_ant]\n",
        "    antecedents_mask = antecedents >= 0 #[num_mentions,max_ant]\n",
        "    antecedents = tf.maximum(antecedents, 0)#[num_mentions,max_ant]\n",
        "    antecedents_emb = tf.gather(mention_emb, antecedents)#[num_mentions,max_ant,4*hidden_size]\n",
        "\n",
        "    #After that,  we concatenate the mentions embeddings with the antecedent \n",
        "    #embeddings to create the mention pair embeddings.\n",
        "    tiled_mention_emb = tf.tile(tf.expand_dims(mention_emb, 1), [1,max_ant,1]) #[num_mentions,max_ant,4*hidden_size]\n",
        "    mention_pair_emb = tf.concat([tiled_mention_emb, antecedents_emb], 2) #[num_mentions,max_ant,8*hidden_size]\n",
        "    ffnn_input = tf.reshape(mention_pair_emb,[num_mention*max_ant, 8 * self.hidden_size]) #[num_mentions*max_ant,8*hidden_size]\n",
        "\n",
        "\n",
        "    #create a multilayer feed-forward neural network to compute mention pair scores.\n",
        "    for i in range(self.ffnn_layer):\n",
        "      hidden_weights = tf.get_variable(\"hidden_weights_{}\".format(i),[shape(ffnn_input,1), self.hidden_size]) #[8*hidden_size,hidden_size] for the first layer [hidden_size,hidden_size] for all the other layer\n",
        "      hidden_bias = tf.get_variable(\"hidden_bias_{}\".format(i), [self.hidden_size]) #[hidden_size]\n",
        "      ffnn_output = tf.nn.relu(tf.nn.xw_plus_b(ffnn_input, hidden_weights,hidden_bias)) #[num_mentions*max_ant, hidden_size]\n",
        "      ffnn_output = tf.nn.dropout(ffnn_output, hidden_keep_prob)#[num_mentions*max_ant, hidden_size]\n",
        "      ffnn_input = ffnn_output#[num_mentions*max_ant, hidden_size]\n",
        "\n",
        "    output_weights = tf.get_variable(\"output_weights\", [shape(ffnn_input, 1), 1]) #[hidden_size,1]\n",
        "    output_bias = tf.get_variable(\"output_bias\", [1]) #[1]\n",
        "    mention_pair_scores = tf.nn.xw_plus_b(ffnn_input,output_weights,output_bias) #[num_mentions*max_ant,1]\n",
        "\n",
        "    mention_pair_scores = tf.reshape(mention_pair_scores,[num_mention,max_ant])#[num_mentions, max_ant]\n",
        "    mention_pair_scores += tf.log(tf.to_float(antecedents_mask))#[num_mentions,max_ant]\n",
        "\n",
        "    dummy_scores = tf.zeros([num_mention,1])#[num_mentions,1]\n",
        "\n",
        "    mention_pair_scores = tf.concat([dummy_scores,mention_pair_scores], 1) #[num_mentions,max_ant+1]\n",
        "\n",
        "    #create the gold label for training\n",
        "    antecedents_cluster_ids = tf.gather(mention_cluster_ids,antecedents) + tf.to_int32(tf.log(tf.to_float(antecedents_mask))) #[num_mentions,max_ant]\n",
        "    mention_pair_labels = tf.logical_and(\n",
        "      tf.equal(antecedents_cluster_ids, tf.expand_dims(mention_cluster_ids, 1)),\n",
        "      tf.greater(antecedents_cluster_ids, 0)) #[num_mentions,max_ant]\n",
        "    dummy_labels = tf.logical_not(tf.reduce_any(mention_pair_labels,1,keepdims=True)) #[num_mentions,1]\n",
        "    mention_pair_labels = tf.concat([dummy_labels,mention_pair_labels],1) #[num_mentions, max_ant+1]\n",
        "    \n",
        "    \n",
        "    #compute the loss\n",
        "    gold_scores = mention_pair_scores + tf.log(tf.to_float(mention_pair_labels)) #[num_mentions, max_ant+1]\n",
        "    marginalized_gold_scores = tf.reduce_logsumexp(gold_scores,1) #[num_mentions]\n",
        "    log_norm = tf.reduce_logsumexp(mention_pair_scores,1) #[num_mentions]\n",
        "    loss = log_norm - marginalized_gold_scores #[num_mentions]\n",
        "    loss = tf.reduce_sum(loss) #[1]\n",
        "\n",
        "    return [antecedents, mention_pair_scores], loss\n",
        "  CorefModel.get_predictions_and_loss = get_predictions_and_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwY6QcxTxn88",
        "colab_type": "text"
      },
      "source": [
        "Finally, the method defines the training mechanism and initializes global variables of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jaWB8QFKyUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def build(self):\n",
        "    #loads pre-trained word embeddings\n",
        "    self.embedding_dict = self.load_embeddings(self.embedding_path, self.embedding_size)\n",
        "    \n",
        "    #create placeholders\n",
        "    self.add_placeholder()\n",
        "\n",
        "    #create tensorflow graph\n",
        "    self.predictions, self.loss = self.get_predictions_and_loss(\n",
        "      self.word_embeddings,self.sent_lengths,self.mention_starts,self.mention_ends,\n",
        "      self.mention_cluster_ids,self.is_training)\n",
        "\n",
        "    #define training mechanism\n",
        "    trainable_params = tf.trainable_variables()\n",
        "    gradients = tf.gradients(self.loss, trainable_params)\n",
        "    gradients, _ = tf.clip_by_global_norm(gradients,5.0)\n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    self.train_op = optimizer.apply_gradients(zip(gradients,trainable_params))\n",
        "    self.sess = tf.Session()\n",
        "    self.sess.run(tf.global_variables_initializer())\n",
        "  CorefModel.build = build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8DBfSxB2fx0",
        "colab_type": "text"
      },
      "source": [
        "###The get_feed_dict_list() method creates inputs for the tensorflow graph.\n",
        "This method reads documents from the the json files and return a list of `feed_dict` elements, which are used as the input for the tensorflow graph. The method also returns the gold clusters of each documents which are used for evaluation.\n",
        "\n",
        "Each of the lines in the json files contains information for a single document. The “doc_key\" stores the name of the document; the “sentences” points you to tokenized sentences of the document; the “clusters” element stores the coreference clusters. Each of the clusters contains a number of mentions, each of the mentions has a start and an end indices which link back to the sentences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfajUPAi3EsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def get_feed_dict_list(self,path, is_training):\n",
        "    feed_dict_list = []\n",
        "    for line in open(path):\n",
        "      doc = json.loads(line)\n",
        "      \n",
        "      #For each document, the method first assigns each mention \n",
        "      #a cluster_id according to the clusters it belongs to:\n",
        "      clusters = doc['clusters']\n",
        "      gold_mentions = sorted([tuple(m) for cl in clusters for m in cl])\n",
        "      gold_mention_map = {m:i for i,m in enumerate(gold_mentions)}\n",
        "      cluster_ids = np.zeros(len(gold_mentions))\n",
        "      for cid, cluster in enumerate(clusters):\n",
        "        for mention in cluster:\n",
        "          cluster_ids[gold_mention_map[tuple(mention)]] = cid + 1\n",
        "      \n",
        "      #It then splits the mentions into two arrays, one representing \n",
        "      #the start indices, and the other for the end indices:\n",
        "      starts, ends = [], []\n",
        "      if len(gold_mentions) > 0:\n",
        "        starts, ends = zip(*gold_mentions)\n",
        "      starts, ends = np.array(starts), np.array(ends)\n",
        "      \n",
        "      #After that,  it reads the word embeddings for the sentences in the document\n",
        "      sentences = doc['sentences']\n",
        "      sent_lengths = [len(sent) for sent in sentences]\n",
        "      max_sent_length = max(sent_lengths)\n",
        "      word_emb = np.zeros([len(sentences),max_sent_length,self.embedding_size])\n",
        "      for i, sent in enumerate(sentences):\n",
        "        for j, word in enumerate(sent):\n",
        "          word_emb[i,j] = self.embedding_dict[word]\n",
        "\n",
        "      #In the end, it creates the feed_dict:\n",
        "      fd = {}\n",
        "      fd[self.word_embeddings] = word_emb\n",
        "      fd[self.sent_lengths] = np.array(sent_lengths)\n",
        "      fd[self.mention_starts] = starts\n",
        "      fd[self.mention_ends] = ends\n",
        "      fd[self.mention_cluster_ids] = cluster_ids\n",
        "      fd[self.is_training] = is_training\n",
        "      feed_dict_list.append(tuple((fd,clusters)))\n",
        "\n",
        "    return feed_dict_list\n",
        "  CorefModel.get_feed_dict_list = get_feed_dict_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yQRxc5t3s66",
        "colab_type": "text"
      },
      "source": [
        "###The get_predicted_clusters() method creates the predicted clusters from the predicted antecedents\n",
        "The outputs of the `get_predictions_and_loss()` method is not yet clusters, instead it returns predicted antecedents, so we need to group them as clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Q-lf-_4D1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def get_predicted_clusters(self, mention_starts, mention_ends, predicted_antecedents):\n",
        "    mention_to_predicted = {}\n",
        "    predicted_clusters = []\n",
        "\n",
        "    for i, predicted_index in enumerate(predicted_antecedents):\n",
        "      if predicted_index < 0:\n",
        "        continue\n",
        "      assert i > predicted_index\n",
        "      predicted_antecedent = (int(mention_starts[predicted_index]), int(mention_ends[predicted_index]))\n",
        "      if predicted_antecedent in mention_to_predicted:\n",
        "        predicted_cluster = mention_to_predicted[predicted_antecedent]\n",
        "      else:\n",
        "        predicted_cluster = len(predicted_clusters)\n",
        "        predicted_clusters.append([predicted_antecedent])\n",
        "        mention_to_predicted[predicted_antecedent] = predicted_cluster\n",
        "\n",
        "      mention = (int(mention_starts[i]), int(mention_ends[i]))\n",
        "      predicted_clusters[predicted_cluster].append(mention)\n",
        "      mention_to_predicted[mention] = predicted_cluster\n",
        "\n",
        "    predicted_clusters = [tuple(pc) for pc in predicted_clusters]\n",
        "    mention_to_predicted = {m: predicted_clusters[i] for m, i in mention_to_predicted.items()}\n",
        "\n",
        "\n",
        "    return predicted_clusters, mention_to_predicted\n",
        "  CorefModel.get_predicted_clusters = get_predicted_clusters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtC6c1UV8i0U",
        "colab_type": "text"
      },
      "source": [
        "###The evaluate_coref() method updates the coreference scorer\n",
        "The method first creates `gold_clusters` and `mention_to_gold` which are required by the coreference scorer. It is important that both clusters and mentions should be tuples in order to be used by the scorer. `mention_to_gold` is the map from mention to clusters. It then creates predicted clusters by calling the `get_predicted_clusters` method. After obtaining both gold and predicted clusters, the method updates the scorer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKaJpyBh85j_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def evaluate_coref(self, mention_starts, mention_ends, predicted_antecedents, gold_clusters, evaluator):\n",
        "    gold_clusters = [tuple(tuple(m) for m in gc) for gc in gold_clusters]\n",
        "    mention_to_gold = {}\n",
        "    for gc in gold_clusters:\n",
        "      for mention in gc:\n",
        "        mention_to_gold[mention] = gc\n",
        "\n",
        "    predicted_clusters, mention_to_predicted = \\\n",
        "    self.get_predicted_clusters(mention_starts, mention_ends,\n",
        "                                  predicted_antecedents)\n",
        "    evaluator.update(predicted_clusters, gold_clusters, mention_to_predicted, mention_to_gold)\n",
        "  CorefModel.evaluate_coref = evaluate_coref"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT3f0kVU9dQs",
        "colab_type": "text"
      },
      "source": [
        "###The train() method oversees the training process.\n",
        "It first loads the training data. Then training the model by go through the all the training documents  a number of times. It also outputs the average loss and time usage of the training.After each epoch, the model evaluates on the development set. Normally, the model will be written to the disk if a better dev score is obtained. Here we didn’t do that to simplify the code for lab use. After finished all the training epochs, it evaluates on the final test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab8iRkXK9prJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def train(self, train_path,dev_path,test_path, epochs):\n",
        "    train_fd_list = self.get_feed_dict_list(train_path, True)\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "      print(\"Starting training epoch {}/{}\".format(epoch+1,epochs))\n",
        "      epoch_time = time.time()\n",
        "      losses = []\n",
        "      for i, (fd, _) in enumerate(train_fd_list):\n",
        "        _,loss = self.sess.run([self.train_op,self.loss], feed_dict=fd)\n",
        "        losses.append(loss)\n",
        "        if i>0 and i%200 == 0:\n",
        "          print(\"[{}]: loss:{:.2f}\".format(i,sum(losses[i-200:])/200.0))\n",
        "      print(\"Average epoch loss:{}\".format(sum(losses)/len(losses)))\n",
        "      print(\"Time used for epoch {}: {}\".format(epoch+1, time_used(epoch_time)))\n",
        "      dev_time = time.time()\n",
        "      print(\"Evaluating on dev set after epoch {}/{}:\".format(epoch+1,epochs))\n",
        "      self.eval(dev_path)\n",
        "      print(\"Time used for evaluate on dev set: {}\".format(time_used(dev_time)))\n",
        "\n",
        "    print(\"Training finished!\")\n",
        "    print(\"Time used for training: {}\".format(time_used(start_time)))\n",
        "\n",
        "    print(\"Evaluating on test set:\")\n",
        "    test_time = time.time()\n",
        "    self.eval(test_path)\n",
        "    print(\"Time used for evaluate on test set: {}\".format(time_used(test_time)))\n",
        "  CorefModel.train = train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45ZQjO6S9uN1",
        "colab_type": "text"
      },
      "source": [
        "###The eval() method runs a test on the given dataset.\n",
        "The method  first reads the dataset. Then, it creates an instance of the coreference scorer. After that,  it evaluates the dataset document by document. In the end, it gets the scores from the coreference scorer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oQMAe7d-B6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def eval(self, path):\n",
        "    eval_fd_list = self.get_feed_dict_list(path, False)\n",
        "    coref_evaluator = CorefEvaluator()\n",
        "\n",
        "    for fd, clusters in eval_fd_list:\n",
        "      mention_starts,mention_ends = fd[self.mention_starts],fd[self.mention_ends]\n",
        "      antecedents, mention_pair_scores = self.sess.run(self.predictions, fd)\n",
        "\n",
        "      predicted_antecedents = []\n",
        "      for i, index in enumerate(np.argmax(mention_pair_scores, axis=1) - 1):\n",
        "        if index < 0:\n",
        "          predicted_antecedents.append(-1)\n",
        "        else:\n",
        "          predicted_antecedents.append(antecedents[i, index])\n",
        "\n",
        "      self.evaluate_coref(mention_starts,mention_ends,predicted_antecedents,clusters,coref_evaluator)\n",
        "\n",
        "    p, r, f = coref_evaluator.get_prf()\n",
        "    print(\"Average F1 (py): {:.2f}%\".format(f * 100))\n",
        "    print(\"Average precision (py): {:.2f}%\".format(p * 100))\n",
        "    print(\"Average recall (py): {:.2f}%\".format(r * 100))\n",
        "  CorefModel.eval = eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwcoddOx-DNR",
        "colab_type": "text"
      },
      "source": [
        "### Finally, the \\__main__ method starts the training.\n",
        "It also configures the model by providing the locations of all the files needed for the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPdPgGKO-Yq8",
        "colab_type": "code",
        "outputId": "f7808f09-de0a-422d-d937-567d0d305be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1482
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  embedding_path = 'model.txt'\n",
        "  train_path = '20MinsNLP-2019-04-02-Coreference-Data/train.english.pd2.0.conll.jsonlines'\n",
        "  dev_path = '20MinsNLP-2019-04-02-Coreference-Data/dev.english.pd2.0.conll.jsonlines'\n",
        "  test_path = '20MinsNLP-2019-04-02-Coreference-Data/test.english.pd2.0.conll.jsonlines'\n",
        "  embedding_size = 300\n",
        "  model = CorefModel(embedding_path,embedding_size)\n",
        "  model.build()\n",
        "  model.train(train_path,dev_path,test_path,5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word embeddings from model.txt...\n",
            "Finished loading word embeddings\n",
            "WARNING:tensorflow:From <ipython-input-8-4186b535e172>:3: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-4186b535e172>:8: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From <ipython-input-8-4186b535e172>:9: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-8-4186b535e172>:19: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1242: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting training epoch 1/5\n",
            "[200]: loss:243.76\n",
            "[400]: loss:247.01\n",
            "Average epoch loss:243.163052473\n",
            "Time used for epoch 1: 1 m 30 s\n",
            "Evaluating on dev set after epoch 1/5:\n",
            "Average F1 (py): 27.29%\n",
            "Average precision (py): 39.09%\n",
            "Average recall (py): 21.09%\n",
            "Time used for evaluate on dev set: 0 m 2 s\n",
            "Starting training epoch 2/5\n",
            "[200]: loss:218.62\n",
            "[400]: loss:228.57\n",
            "Average epoch loss:222.593025735\n",
            "Time used for epoch 2: 1 m 27 s\n",
            "Evaluating on dev set after epoch 2/5:\n",
            "Average F1 (py): 37.01%\n",
            "Average precision (py): 40.79%\n",
            "Average recall (py): 34.68%\n",
            "Time used for evaluate on dev set: 0 m 2 s\n",
            "Starting training epoch 3/5\n",
            "[200]: loss:205.84\n",
            "[400]: loss:217.68\n",
            "Average epoch loss:211.102821932\n",
            "Time used for epoch 3: 1 m 27 s\n",
            "Evaluating on dev set after epoch 3/5:\n",
            "Average F1 (py): 42.65%\n",
            "Average precision (py): 45.23%\n",
            "Average recall (py): 41.62%\n",
            "Time used for evaluate on dev set: 0 m 2 s\n",
            "Starting training epoch 4/5\n",
            "[200]: loss:196.30\n",
            "[400]: loss:210.99\n",
            "Average epoch loss:202.895985329\n",
            "Time used for epoch 4: 1 m 27 s\n",
            "Evaluating on dev set after epoch 4/5:\n",
            "Average F1 (py): 44.80%\n",
            "Average precision (py): 46.93%\n",
            "Average recall (py): 45.61%\n",
            "Time used for evaluate on dev set: 0 m 2 s\n",
            "Starting training epoch 5/5\n",
            "[200]: loss:191.08\n",
            "[400]: loss:205.86\n",
            "Average epoch loss:197.592686312\n",
            "Time used for epoch 5: 1 m 26 s\n",
            "Evaluating on dev set after epoch 5/5:\n",
            "Average F1 (py): 44.53%\n",
            "Average precision (py): 46.95%\n",
            "Average recall (py): 44.86%\n",
            "Time used for evaluate on dev set: 0 m 2 s\n",
            "Training finished!\n",
            "Time used for training: 7 m 29 s\n",
            "Evaluating on test set:\n",
            "Average F1 (py): 48.34%\n",
            "Average precision (py): 51.17%\n",
            "Average recall (py): 49.22%\n",
            "Time used for evaluate on test set: 0 m 3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lku-gV-A-hpF",
        "colab_type": "text"
      },
      "source": [
        "##Further readings about the state-of-the-art coreference systems\n",
        "[\"End-to-end Neural Coreference Resolution\"](http://kentonl.com/pub/lhlz-emnlp.2017.pdf).\n",
        "Kenton Lee, Luheng He, Mike Lewis, Luke Zettlemoyer.\n",
        "EMNLP 2017.\n",
        "\n",
        "[\"Higher-order Coreference Resolution with Coarse-to-fine Inference\"](https://arxiv.org/abs/1804.05392). \n",
        "Kenton Lee, Luheng He, Luke Zettlemoyer.\n",
        "NAACL 2018.\n",
        "\n",
        "[\"Deep Reinforcement Learning for Mention-Ranking Coreference Models\"](http://cs.stanford.edu/people/kevclark/resources/clark-manning-emnlp2016-deep.pdf). Kevin Clark and Christopher D. Manning. EMNLP 2016.\n",
        "\n",
        "[\"Improving Coreference Resolution by Learning Entity-Level Distributed Representations\"](http://cs.stanford.edu/people/kevclark/resources/clark-manning-acl16-improving.pdf). Kevin Clark and Christopher D. Manning. ACL 2016."
      ]
    }
  ]
}